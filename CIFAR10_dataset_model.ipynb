{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10-dataset-model",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajc-i8XbHP1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D,MaxPooling2D\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9fnNaSXJP3c",
        "colab_type": "text"
      },
      "source": [
        "## Loading the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZnWFXWSJpBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test ) = cifar10.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm8N3CbWTei6",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq_u3TM6Vweu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype(\"float32\")\n",
        "X_test = X_test.astype(\"float32\")\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "\n",
        "## Converting our labels from 0-9 to the array of the binary label with index to 1 whici is label and all other to zero\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ4fj3liXe0h",
        "colab_type": "text"
      },
      "source": [
        "## Creatting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Tb5X6NYYYN",
        "colab_type": "code",
        "outputId": "2dea7a36-7797-4329-c5d6-5fdf55fb6948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "\ttf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)),\n",
        "\ttf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "\ttf.keras.layers.MaxPooling2D(2, 2),\n",
        "\ttf.keras.layers.Dropout(0.25),\n",
        "\ttf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "\ttf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "\ttf.keras.layers.MaxPooling2D(2, 2),\n",
        "\ttf.keras.layers.Dropout(0.25),\n",
        "\ttf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "\ttf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "\ttf.keras.layers.MaxPooling2D(2, 2),\n",
        "\ttf.keras.layers.Dropout(0.25),\n",
        "\ttf.keras.layers.Flatten(),\n",
        "\ttf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
        "\ttf.keras.layers.Dropout(0.5),\n",
        "\ttf.keras.layers.Dense(10, activation='softmax'),\n",
        "               \n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_30 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 550,570\n",
            "Trainable params: 550,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pPOi2u6bgV_",
        "colab_type": "text"
      },
      "source": [
        "## Compiling the Neural Network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0H-GzPpbvcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics = ['accuracy']\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWg0KaaHb5K1",
        "colab_type": "text"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMAm6e3Jb-Y-",
        "colab_type": "code",
        "outputId": "352a7849-8469-4bf9-a031-c92c515cbcb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size = 64,\n",
        "    epochs = 200,\n",
        "    validation_data = (X_test, y_test),\n",
        "    shuffle = True\n",
        ")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.2099 - accuracy: 0.1605 - val_loss: 1.9932 - val_accuracy: 0.2819\n",
            "Epoch 2/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.8946 - accuracy: 0.2873 - val_loss: 1.7040 - val_accuracy: 0.3820\n",
            "Epoch 3/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.7367 - accuracy: 0.3479 - val_loss: 1.6005 - val_accuracy: 0.4112\n",
            "Epoch 4/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6334 - accuracy: 0.3915 - val_loss: 1.4820 - val_accuracy: 0.4586\n",
            "Epoch 5/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.5542 - accuracy: 0.4241 - val_loss: 1.4518 - val_accuracy: 0.4697\n",
            "Epoch 6/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4873 - accuracy: 0.4509 - val_loss: 1.3443 - val_accuracy: 0.5117\n",
            "Epoch 7/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4390 - accuracy: 0.4746 - val_loss: 1.3295 - val_accuracy: 0.5182\n",
            "Epoch 8/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3908 - accuracy: 0.4916 - val_loss: 1.2770 - val_accuracy: 0.5326\n",
            "Epoch 9/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3481 - accuracy: 0.5121 - val_loss: 1.1984 - val_accuracy: 0.5731\n",
            "Epoch 10/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3080 - accuracy: 0.5266 - val_loss: 1.1648 - val_accuracy: 0.5833\n",
            "Epoch 11/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2667 - accuracy: 0.5421 - val_loss: 1.1280 - val_accuracy: 0.5914\n",
            "Epoch 12/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2236 - accuracy: 0.5592 - val_loss: 1.0926 - val_accuracy: 0.6123\n",
            "Epoch 13/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1910 - accuracy: 0.5738 - val_loss: 1.0250 - val_accuracy: 0.6353\n",
            "Epoch 14/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1552 - accuracy: 0.5887 - val_loss: 1.0169 - val_accuracy: 0.6348\n",
            "Epoch 15/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1179 - accuracy: 0.6014 - val_loss: 0.9874 - val_accuracy: 0.6453\n",
            "Epoch 16/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0896 - accuracy: 0.6128 - val_loss: 1.0162 - val_accuracy: 0.6458\n",
            "Epoch 17/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0612 - accuracy: 0.6225 - val_loss: 0.9340 - val_accuracy: 0.6659\n",
            "Epoch 18/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0380 - accuracy: 0.6321 - val_loss: 0.9276 - val_accuracy: 0.6695\n",
            "Epoch 19/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0183 - accuracy: 0.6397 - val_loss: 0.8764 - val_accuracy: 0.6889\n",
            "Epoch 20/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9950 - accuracy: 0.6484 - val_loss: 0.8751 - val_accuracy: 0.6909\n",
            "Epoch 21/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9764 - accuracy: 0.6554 - val_loss: 0.8579 - val_accuracy: 0.6924\n",
            "Epoch 22/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9559 - accuracy: 0.6644 - val_loss: 0.8341 - val_accuracy: 0.7017\n",
            "Epoch 23/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9352 - accuracy: 0.6718 - val_loss: 0.8275 - val_accuracy: 0.7061\n",
            "Epoch 24/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9205 - accuracy: 0.6766 - val_loss: 0.8718 - val_accuracy: 0.6862\n",
            "Epoch 25/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8996 - accuracy: 0.6835 - val_loss: 0.7867 - val_accuracy: 0.7202\n",
            "Epoch 26/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8887 - accuracy: 0.6865 - val_loss: 0.7590 - val_accuracy: 0.7355\n",
            "Epoch 27/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8743 - accuracy: 0.6933 - val_loss: 0.8036 - val_accuracy: 0.7105\n",
            "Epoch 28/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8600 - accuracy: 0.6999 - val_loss: 0.7399 - val_accuracy: 0.7396\n",
            "Epoch 29/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8455 - accuracy: 0.7028 - val_loss: 0.7620 - val_accuracy: 0.7270\n",
            "Epoch 30/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8306 - accuracy: 0.7101 - val_loss: 0.7372 - val_accuracy: 0.7359\n",
            "Epoch 31/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8208 - accuracy: 0.7118 - val_loss: 0.7461 - val_accuracy: 0.7350\n",
            "Epoch 32/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8052 - accuracy: 0.7188 - val_loss: 0.7045 - val_accuracy: 0.7519\n",
            "Epoch 33/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7927 - accuracy: 0.7239 - val_loss: 0.6912 - val_accuracy: 0.7544\n",
            "Epoch 34/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7814 - accuracy: 0.7270 - val_loss: 0.6893 - val_accuracy: 0.7569\n",
            "Epoch 35/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7760 - accuracy: 0.7271 - val_loss: 0.6931 - val_accuracy: 0.7556\n",
            "Epoch 36/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7651 - accuracy: 0.7300 - val_loss: 0.6890 - val_accuracy: 0.7590\n",
            "Epoch 37/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7507 - accuracy: 0.7353 - val_loss: 0.6732 - val_accuracy: 0.7658\n",
            "Epoch 38/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7490 - accuracy: 0.7358 - val_loss: 0.6602 - val_accuracy: 0.7644\n",
            "Epoch 39/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7335 - accuracy: 0.7438 - val_loss: 0.6697 - val_accuracy: 0.7627\n",
            "Epoch 40/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7259 - accuracy: 0.7486 - val_loss: 0.6791 - val_accuracy: 0.7613\n",
            "Epoch 41/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7163 - accuracy: 0.7476 - val_loss: 0.6532 - val_accuracy: 0.7742\n",
            "Epoch 42/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7133 - accuracy: 0.7507 - val_loss: 0.6362 - val_accuracy: 0.7736\n",
            "Epoch 43/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7028 - accuracy: 0.7545 - val_loss: 0.6363 - val_accuracy: 0.7784\n",
            "Epoch 44/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7038 - accuracy: 0.7571 - val_loss: 0.6316 - val_accuracy: 0.7788\n",
            "Epoch 45/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6864 - accuracy: 0.7603 - val_loss: 0.6403 - val_accuracy: 0.7791\n",
            "Epoch 46/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6843 - accuracy: 0.7604 - val_loss: 0.6147 - val_accuracy: 0.7839\n",
            "Epoch 47/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6706 - accuracy: 0.7660 - val_loss: 0.6263 - val_accuracy: 0.7795\n",
            "Epoch 48/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6636 - accuracy: 0.7693 - val_loss: 0.6056 - val_accuracy: 0.7894\n",
            "Epoch 49/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6555 - accuracy: 0.7708 - val_loss: 0.6074 - val_accuracy: 0.7869\n",
            "Epoch 50/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6484 - accuracy: 0.7741 - val_loss: 0.5887 - val_accuracy: 0.7952\n",
            "Epoch 51/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6470 - accuracy: 0.7757 - val_loss: 0.6158 - val_accuracy: 0.7849\n",
            "Epoch 52/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6383 - accuracy: 0.7782 - val_loss: 0.5882 - val_accuracy: 0.7947\n",
            "Epoch 53/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6330 - accuracy: 0.7795 - val_loss: 0.6024 - val_accuracy: 0.7897\n",
            "Epoch 54/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6260 - accuracy: 0.7802 - val_loss: 0.5800 - val_accuracy: 0.7941\n",
            "Epoch 55/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6157 - accuracy: 0.7857 - val_loss: 0.5789 - val_accuracy: 0.7981\n",
            "Epoch 56/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6144 - accuracy: 0.7855 - val_loss: 0.5940 - val_accuracy: 0.7941\n",
            "Epoch 57/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6052 - accuracy: 0.7905 - val_loss: 0.5879 - val_accuracy: 0.7969\n",
            "Epoch 58/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6008 - accuracy: 0.7907 - val_loss: 0.5688 - val_accuracy: 0.8035\n",
            "Epoch 59/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5953 - accuracy: 0.7898 - val_loss: 0.5675 - val_accuracy: 0.8058\n",
            "Epoch 60/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5948 - accuracy: 0.7942 - val_loss: 0.5660 - val_accuracy: 0.8028\n",
            "Epoch 61/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5830 - accuracy: 0.7953 - val_loss: 0.5770 - val_accuracy: 0.8030\n",
            "Epoch 62/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5826 - accuracy: 0.7968 - val_loss: 0.5606 - val_accuracy: 0.8085\n",
            "Epoch 63/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5758 - accuracy: 0.8012 - val_loss: 0.5491 - val_accuracy: 0.8118\n",
            "Epoch 64/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5725 - accuracy: 0.8014 - val_loss: 0.5525 - val_accuracy: 0.8123\n",
            "Epoch 65/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5651 - accuracy: 0.8034 - val_loss: 0.5509 - val_accuracy: 0.8106\n",
            "Epoch 66/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5605 - accuracy: 0.8043 - val_loss: 0.5566 - val_accuracy: 0.8102\n",
            "Epoch 67/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5542 - accuracy: 0.8081 - val_loss: 0.5566 - val_accuracy: 0.8082\n",
            "Epoch 68/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5477 - accuracy: 0.8099 - val_loss: 0.5542 - val_accuracy: 0.8097\n",
            "Epoch 69/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5470 - accuracy: 0.8084 - val_loss: 0.5463 - val_accuracy: 0.8120\n",
            "Epoch 70/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5383 - accuracy: 0.8109 - val_loss: 0.5466 - val_accuracy: 0.8147\n",
            "Epoch 71/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5389 - accuracy: 0.8116 - val_loss: 0.5329 - val_accuracy: 0.8174\n",
            "Epoch 72/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5312 - accuracy: 0.8162 - val_loss: 0.5448 - val_accuracy: 0.8135\n",
            "Epoch 73/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5277 - accuracy: 0.8155 - val_loss: 0.5347 - val_accuracy: 0.8172\n",
            "Epoch 74/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5225 - accuracy: 0.8184 - val_loss: 0.5322 - val_accuracy: 0.8194\n",
            "Epoch 75/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5187 - accuracy: 0.8196 - val_loss: 0.5406 - val_accuracy: 0.8187\n",
            "Epoch 76/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5175 - accuracy: 0.8205 - val_loss: 0.5375 - val_accuracy: 0.8172\n",
            "Epoch 77/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5122 - accuracy: 0.8194 - val_loss: 0.5496 - val_accuracy: 0.8139\n",
            "Epoch 78/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5043 - accuracy: 0.8241 - val_loss: 0.5337 - val_accuracy: 0.8176\n",
            "Epoch 79/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5060 - accuracy: 0.8232 - val_loss: 0.5205 - val_accuracy: 0.8195\n",
            "Epoch 80/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4980 - accuracy: 0.8266 - val_loss: 0.5347 - val_accuracy: 0.8186\n",
            "Epoch 81/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4931 - accuracy: 0.8270 - val_loss: 0.5340 - val_accuracy: 0.8193\n",
            "Epoch 82/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4853 - accuracy: 0.8279 - val_loss: 0.5301 - val_accuracy: 0.8199\n",
            "Epoch 83/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4894 - accuracy: 0.8292 - val_loss: 0.5292 - val_accuracy: 0.8207\n",
            "Epoch 84/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4840 - accuracy: 0.8325 - val_loss: 0.5411 - val_accuracy: 0.8191\n",
            "Epoch 85/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4776 - accuracy: 0.8332 - val_loss: 0.5258 - val_accuracy: 0.8200\n",
            "Epoch 86/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4754 - accuracy: 0.8342 - val_loss: 0.5215 - val_accuracy: 0.8245\n",
            "Epoch 87/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4676 - accuracy: 0.8363 - val_loss: 0.5023 - val_accuracy: 0.8303\n",
            "Epoch 88/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4683 - accuracy: 0.8356 - val_loss: 0.5109 - val_accuracy: 0.8278\n",
            "Epoch 89/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4658 - accuracy: 0.8362 - val_loss: 0.4985 - val_accuracy: 0.8306\n",
            "Epoch 90/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4628 - accuracy: 0.8395 - val_loss: 0.5125 - val_accuracy: 0.8281\n",
            "Epoch 91/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4566 - accuracy: 0.8414 - val_loss: 0.5128 - val_accuracy: 0.8283\n",
            "Epoch 92/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4574 - accuracy: 0.8416 - val_loss: 0.5087 - val_accuracy: 0.8288\n",
            "Epoch 93/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4505 - accuracy: 0.8421 - val_loss: 0.5074 - val_accuracy: 0.8291\n",
            "Epoch 94/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4519 - accuracy: 0.8401 - val_loss: 0.5127 - val_accuracy: 0.8288\n",
            "Epoch 95/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4436 - accuracy: 0.8427 - val_loss: 0.5002 - val_accuracy: 0.8292\n",
            "Epoch 96/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4373 - accuracy: 0.8458 - val_loss: 0.4928 - val_accuracy: 0.8334\n",
            "Epoch 97/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4337 - accuracy: 0.8461 - val_loss: 0.5128 - val_accuracy: 0.8323\n",
            "Epoch 98/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4342 - accuracy: 0.8469 - val_loss: 0.5000 - val_accuracy: 0.8319\n",
            "Epoch 99/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4311 - accuracy: 0.8481 - val_loss: 0.5076 - val_accuracy: 0.8274\n",
            "Epoch 100/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4239 - accuracy: 0.8487 - val_loss: 0.5181 - val_accuracy: 0.8300\n",
            "Epoch 101/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4223 - accuracy: 0.8513 - val_loss: 0.4946 - val_accuracy: 0.8358\n",
            "Epoch 102/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4274 - accuracy: 0.8493 - val_loss: 0.5074 - val_accuracy: 0.8312\n",
            "Epoch 103/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4216 - accuracy: 0.8517 - val_loss: 0.4927 - val_accuracy: 0.8350\n",
            "Epoch 104/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4195 - accuracy: 0.8525 - val_loss: 0.5196 - val_accuracy: 0.8274\n",
            "Epoch 105/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4098 - accuracy: 0.8572 - val_loss: 0.4981 - val_accuracy: 0.8310\n",
            "Epoch 106/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4113 - accuracy: 0.8545 - val_loss: 0.5129 - val_accuracy: 0.8327\n",
            "Epoch 107/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4111 - accuracy: 0.8557 - val_loss: 0.5000 - val_accuracy: 0.8343\n",
            "Epoch 108/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4087 - accuracy: 0.8558 - val_loss: 0.4909 - val_accuracy: 0.8359\n",
            "Epoch 109/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4037 - accuracy: 0.8581 - val_loss: 0.5158 - val_accuracy: 0.8322\n",
            "Epoch 110/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3967 - accuracy: 0.8595 - val_loss: 0.5302 - val_accuracy: 0.8308\n",
            "Epoch 111/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3964 - accuracy: 0.8607 - val_loss: 0.5191 - val_accuracy: 0.8324\n",
            "Epoch 112/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3957 - accuracy: 0.8606 - val_loss: 0.4884 - val_accuracy: 0.8421\n",
            "Epoch 113/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3865 - accuracy: 0.8637 - val_loss: 0.5110 - val_accuracy: 0.8313\n",
            "Epoch 114/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3902 - accuracy: 0.8614 - val_loss: 0.4834 - val_accuracy: 0.8390\n",
            "Epoch 115/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3835 - accuracy: 0.8650 - val_loss: 0.4949 - val_accuracy: 0.8394\n",
            "Epoch 116/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3851 - accuracy: 0.8638 - val_loss: 0.4888 - val_accuracy: 0.8389\n",
            "Epoch 117/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3813 - accuracy: 0.8663 - val_loss: 0.4926 - val_accuracy: 0.8379\n",
            "Epoch 118/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3805 - accuracy: 0.8659 - val_loss: 0.4926 - val_accuracy: 0.8379\n",
            "Epoch 119/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3778 - accuracy: 0.8660 - val_loss: 0.5063 - val_accuracy: 0.8327\n",
            "Epoch 120/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3769 - accuracy: 0.8677 - val_loss: 0.4822 - val_accuracy: 0.8400\n",
            "Epoch 121/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3730 - accuracy: 0.8678 - val_loss: 0.5008 - val_accuracy: 0.8374\n",
            "Epoch 122/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3672 - accuracy: 0.8704 - val_loss: 0.4851 - val_accuracy: 0.8403\n",
            "Epoch 123/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3638 - accuracy: 0.8708 - val_loss: 0.5022 - val_accuracy: 0.8380\n",
            "Epoch 124/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3670 - accuracy: 0.8725 - val_loss: 0.4996 - val_accuracy: 0.8373\n",
            "Epoch 125/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3591 - accuracy: 0.8724 - val_loss: 0.4823 - val_accuracy: 0.8425\n",
            "Epoch 126/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3570 - accuracy: 0.8737 - val_loss: 0.4905 - val_accuracy: 0.8422\n",
            "Epoch 127/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3563 - accuracy: 0.8743 - val_loss: 0.4950 - val_accuracy: 0.8414\n",
            "Epoch 128/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3552 - accuracy: 0.8745 - val_loss: 0.4992 - val_accuracy: 0.8372\n",
            "Epoch 129/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3493 - accuracy: 0.8764 - val_loss: 0.4953 - val_accuracy: 0.8399\n",
            "Epoch 130/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3495 - accuracy: 0.8766 - val_loss: 0.4922 - val_accuracy: 0.8405\n",
            "Epoch 131/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3478 - accuracy: 0.8770 - val_loss: 0.5143 - val_accuracy: 0.8362\n",
            "Epoch 132/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3432 - accuracy: 0.8781 - val_loss: 0.5030 - val_accuracy: 0.8426\n",
            "Epoch 133/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3458 - accuracy: 0.8783 - val_loss: 0.4919 - val_accuracy: 0.8368\n",
            "Epoch 134/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3410 - accuracy: 0.8779 - val_loss: 0.4991 - val_accuracy: 0.8445\n",
            "Epoch 135/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3378 - accuracy: 0.8797 - val_loss: 0.4917 - val_accuracy: 0.8407\n",
            "Epoch 136/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3401 - accuracy: 0.8799 - val_loss: 0.4962 - val_accuracy: 0.8423\n",
            "Epoch 137/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3355 - accuracy: 0.8814 - val_loss: 0.4921 - val_accuracy: 0.8442\n",
            "Epoch 138/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3304 - accuracy: 0.8829 - val_loss: 0.4894 - val_accuracy: 0.8438\n",
            "Epoch 139/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3255 - accuracy: 0.8852 - val_loss: 0.4980 - val_accuracy: 0.8427\n",
            "Epoch 140/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3271 - accuracy: 0.8833 - val_loss: 0.4891 - val_accuracy: 0.8450\n",
            "Epoch 141/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3264 - accuracy: 0.8832 - val_loss: 0.5088 - val_accuracy: 0.8399\n",
            "Epoch 142/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3271 - accuracy: 0.8840 - val_loss: 0.4877 - val_accuracy: 0.8458\n",
            "Epoch 143/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3269 - accuracy: 0.8847 - val_loss: 0.4903 - val_accuracy: 0.8497\n",
            "Epoch 144/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3201 - accuracy: 0.8859 - val_loss: 0.4980 - val_accuracy: 0.8443\n",
            "Epoch 145/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3243 - accuracy: 0.8843 - val_loss: 0.4924 - val_accuracy: 0.8435\n",
            "Epoch 146/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3145 - accuracy: 0.8869 - val_loss: 0.4863 - val_accuracy: 0.8429\n",
            "Epoch 147/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3165 - accuracy: 0.8884 - val_loss: 0.4946 - val_accuracy: 0.8471\n",
            "Epoch 148/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3092 - accuracy: 0.8903 - val_loss: 0.5037 - val_accuracy: 0.8465\n",
            "Epoch 149/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3125 - accuracy: 0.8877 - val_loss: 0.4955 - val_accuracy: 0.8450\n",
            "Epoch 150/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3118 - accuracy: 0.8884 - val_loss: 0.4894 - val_accuracy: 0.8477\n",
            "Epoch 151/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3047 - accuracy: 0.8921 - val_loss: 0.4907 - val_accuracy: 0.8431\n",
            "Epoch 152/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3083 - accuracy: 0.8905 - val_loss: 0.4966 - val_accuracy: 0.8444\n",
            "Epoch 153/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3024 - accuracy: 0.8933 - val_loss: 0.4933 - val_accuracy: 0.8445\n",
            "Epoch 154/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3015 - accuracy: 0.8943 - val_loss: 0.4987 - val_accuracy: 0.8427\n",
            "Epoch 155/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3015 - accuracy: 0.8929 - val_loss: 0.4964 - val_accuracy: 0.8476\n",
            "Epoch 156/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2948 - accuracy: 0.8940 - val_loss: 0.4983 - val_accuracy: 0.8495\n",
            "Epoch 157/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3020 - accuracy: 0.8926 - val_loss: 0.4961 - val_accuracy: 0.8433\n",
            "Epoch 158/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3002 - accuracy: 0.8938 - val_loss: 0.5007 - val_accuracy: 0.8460\n",
            "Epoch 159/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2962 - accuracy: 0.8935 - val_loss: 0.4958 - val_accuracy: 0.8462\n",
            "Epoch 160/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2884 - accuracy: 0.8977 - val_loss: 0.5109 - val_accuracy: 0.8458\n",
            "Epoch 161/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2937 - accuracy: 0.8964 - val_loss: 0.5001 - val_accuracy: 0.8449\n",
            "Epoch 162/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2853 - accuracy: 0.8971 - val_loss: 0.5217 - val_accuracy: 0.8423\n",
            "Epoch 163/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2851 - accuracy: 0.8985 - val_loss: 0.5054 - val_accuracy: 0.8466\n",
            "Epoch 164/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2826 - accuracy: 0.8995 - val_loss: 0.4933 - val_accuracy: 0.8504\n",
            "Epoch 165/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2817 - accuracy: 0.9003 - val_loss: 0.5032 - val_accuracy: 0.8453\n",
            "Epoch 166/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2837 - accuracy: 0.8998 - val_loss: 0.5065 - val_accuracy: 0.8463\n",
            "Epoch 167/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2795 - accuracy: 0.9002 - val_loss: 0.5193 - val_accuracy: 0.8418\n",
            "Epoch 168/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2791 - accuracy: 0.9005 - val_loss: 0.5064 - val_accuracy: 0.8429\n",
            "Epoch 169/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2745 - accuracy: 0.9012 - val_loss: 0.4973 - val_accuracy: 0.8461\n",
            "Epoch 170/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2728 - accuracy: 0.9029 - val_loss: 0.5195 - val_accuracy: 0.8463\n",
            "Epoch 171/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2770 - accuracy: 0.9001 - val_loss: 0.5134 - val_accuracy: 0.8495\n",
            "Epoch 172/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2698 - accuracy: 0.9043 - val_loss: 0.5063 - val_accuracy: 0.8471\n",
            "Epoch 173/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2692 - accuracy: 0.9027 - val_loss: 0.4981 - val_accuracy: 0.8511\n",
            "Epoch 174/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2667 - accuracy: 0.9036 - val_loss: 0.5251 - val_accuracy: 0.8432\n",
            "Epoch 175/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2686 - accuracy: 0.9045 - val_loss: 0.5351 - val_accuracy: 0.8416\n",
            "Epoch 176/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2643 - accuracy: 0.9056 - val_loss: 0.5097 - val_accuracy: 0.8469\n",
            "Epoch 177/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2619 - accuracy: 0.9064 - val_loss: 0.5176 - val_accuracy: 0.8482\n",
            "Epoch 178/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2643 - accuracy: 0.9055 - val_loss: 0.5047 - val_accuracy: 0.8482\n",
            "Epoch 179/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2596 - accuracy: 0.9066 - val_loss: 0.4993 - val_accuracy: 0.8460\n",
            "Epoch 180/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2659 - accuracy: 0.9042 - val_loss: 0.5135 - val_accuracy: 0.8443\n",
            "Epoch 181/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2570 - accuracy: 0.9071 - val_loss: 0.5091 - val_accuracy: 0.8480\n",
            "Epoch 182/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2612 - accuracy: 0.9070 - val_loss: 0.5322 - val_accuracy: 0.8426\n",
            "Epoch 183/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2548 - accuracy: 0.9089 - val_loss: 0.4972 - val_accuracy: 0.8491\n",
            "Epoch 184/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2564 - accuracy: 0.9082 - val_loss: 0.5028 - val_accuracy: 0.8495\n",
            "Epoch 185/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2545 - accuracy: 0.9094 - val_loss: 0.4991 - val_accuracy: 0.8509\n",
            "Epoch 186/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2527 - accuracy: 0.9098 - val_loss: 0.5151 - val_accuracy: 0.8447\n",
            "Epoch 187/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2478 - accuracy: 0.9113 - val_loss: 0.5119 - val_accuracy: 0.8469\n",
            "Epoch 188/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2496 - accuracy: 0.9104 - val_loss: 0.5025 - val_accuracy: 0.8518\n",
            "Epoch 189/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2452 - accuracy: 0.9121 - val_loss: 0.5042 - val_accuracy: 0.8481\n",
            "Epoch 190/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2508 - accuracy: 0.9105 - val_loss: 0.5299 - val_accuracy: 0.8479\n",
            "Epoch 191/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2471 - accuracy: 0.9111 - val_loss: 0.5197 - val_accuracy: 0.8487\n",
            "Epoch 192/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2443 - accuracy: 0.9122 - val_loss: 0.5014 - val_accuracy: 0.8526\n",
            "Epoch 193/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2443 - accuracy: 0.9132 - val_loss: 0.5273 - val_accuracy: 0.8437\n",
            "Epoch 194/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2468 - accuracy: 0.9125 - val_loss: 0.5123 - val_accuracy: 0.8497\n",
            "Epoch 195/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2369 - accuracy: 0.9153 - val_loss: 0.5176 - val_accuracy: 0.8481\n",
            "Epoch 196/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2394 - accuracy: 0.9140 - val_loss: 0.5183 - val_accuracy: 0.8521\n",
            "Epoch 197/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2417 - accuracy: 0.9138 - val_loss: 0.5250 - val_accuracy: 0.8470\n",
            "Epoch 198/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2369 - accuracy: 0.9152 - val_loss: 0.5192 - val_accuracy: 0.8486\n",
            "Epoch 199/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2344 - accuracy: 0.9164 - val_loss: 0.5095 - val_accuracy: 0.8490\n",
            "Epoch 200/200\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2341 - accuracy: 0.9162 - val_loss: 0.5467 - val_accuracy: 0.8468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaSNmb4jcRs8",
        "colab_type": "text"
      },
      "source": [
        "## Making prediction on the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSypHZIKdlGo",
        "colab_type": "code",
        "outputId": "f6b47453-b2b6-4ea2-91ca-5a686c756fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "class_labels = [\n",
        "                \"plane\",\n",
        "                \"car\",\n",
        "                \"bird\",\n",
        "                \"cat\",\n",
        "                \"deer\",\n",
        "                \"dog\",\n",
        "                \"frog\",\n",
        "                \"horse\",\n",
        "                \"boat\",\n",
        "                \"truck\"\n",
        "]\n",
        "\n",
        "img = image.load_img(\"/content/drive/My Drive/linkdin-notebook/cat.png\", target_size=(32, 32))\n",
        "\n",
        "image_test = image.img_to_array(img)\n",
        "\n",
        "list_image = np.expand_dims(image_test, axis = 0)\n",
        "\n",
        "#list_image = list_image.astype(\"float32\")\n",
        "results = model.predict(list_image)\n",
        "\n",
        "single_result = results[0]\n",
        "\n",
        "most_likely_class_index = int(np.argmax(single_result))\n",
        "class_likelihood = single_result[most_likely_class_index]\n",
        "\n",
        "class_label = class_labels[most_likely_class_index]\n",
        "\n",
        "print(\"This is image is a {} - Likelihood: {:2f}\".format(class_label, class_likelihood))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is image is a cat - Likelihood: 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6IOs7PHW8gq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "872fe8bf-35ed-4f6a-86a8-f7acb89a14e0"
      },
      "source": [
        "single_result"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43WvWOk7Q-Kh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d32d618c-603c-4af2-f2aa-b563832d85ce"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], color = 'blue', label = \"train\")\n",
        "plt.plot(history.history['val_loss'], color = \"orange\", label = 'test')\n",
        "\n",
        "\n",
        "plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "plt.plot(history.history['val_accuracy'], color='orange', label='test')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f02b8090c18>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02fvusXD90wn",
        "colab_type": "text"
      },
      "source": [
        "## Using the vgg16 model to predict the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfyuCyK0UObf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "15b73b63-b04b-43b7-889c-1ef8bf3616fe"
      },
      "source": [
        "## Using the pretrained model for image recognition\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import vgg16\n",
        "\n",
        "#load keras vgg16 model that was pretrained against the imageNet database\n",
        "model = vgg16.VGG16()\n",
        "\n",
        "# load the image file , resizing it to 224*224\n",
        "img = image.load_img(\"/content/drive/My Drive/linkdin-notebook/animal-pet-cute-kitten-45201.jpg\", target_size = (224,224))\n",
        "\n",
        "# convert the image to a numpy array\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "# Add a fourth dimensions( since keras expect the list of images)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "#Normalize the imput pixel value to the range used when training the neural network\n",
        "x = vgg16.preprocess_input(x)\n",
        "\n",
        "# Run the image through the deep neural network to make the prediction\n",
        "predictions = model.predict(x)\n",
        "\n",
        "# Look the the names of predicted classes index zero is the result for the first prediction\n",
        "predicted_classes = vgg16.decode_predictions(predictions, top=9)\n",
        "\n",
        "for imagenet_id, name, liklihood in predicted_classes[0]:\n",
        "  print(\"predictions: {} - {:2f}\".format(name, liklihood))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictions: Egyptian_cat - 0.388283\n",
            "predictions: tabby - 0.287608\n",
            "predictions: lynx - 0.109123\n",
            "predictions: Persian_cat - 0.079098\n",
            "predictions: tiger_cat - 0.061431\n",
            "predictions: laptop - 0.007686\n",
            "predictions: computer_keyboard - 0.005566\n",
            "predictions: doormat - 0.005422\n",
            "predictions: notebook - 0.004927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBojl5kUbWGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}